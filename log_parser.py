import re
import csv
import os
from collections import defaultdict

def parse_log_to_csv(log_file_path, output_dir):
    """
    Parses a log file generated by the CLI, extracting raw sensor data,
    category timing data, and command responses into separate CSV files.

    Args:
        log_file_path (str): The full path to the input log file (e.g., 'Work.log').
        output_dir (str): The path to the directory where CSV files will be saved.
    """
    print(f"Starting parsing of log file: {log_file_path}")

    # --- Regular Expressions for New Log Format ---
    # Example line: 2025-07-21 11:56:46.580 - DEBUG - [RAW SENSOR] Pressure ID 1: Values=(0.11137725412845612,), Timing Duration=204 us
    # CHANGED: Added \.\d{3} to the timestamp regex to capture milliseconds.
    log_line_regex = re.compile(r"^(\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}\.\d{3})\s-\s(INFO|DEBUG|WARNING|ERROR|CRITICAL)\s-\s(.*)$")

    # [RAW SENSOR] Pressure ID 0: Values=(0.16,), Timing Duration=496 us
    raw_sensor_regex = re.compile(r"\[RAW SENSOR\]\s(.+?)\sID\s(\d+):\sValues=\((.+?)\),\sTiming\sDuration=(\d+)\sus")

    # [RAW TIMING] Type=0x02, CategoryID=0, Duration=496 us
    raw_timing_category_regex = re.compile(r"\[RAW TIMING\]\sType=(0x[0-9a-fA-F]+),\sCategoryID=(\d+),\sDuration=(\d+)\sus")

    # [RAW RESPONSE] CmdType=0x01, TargetID=0, Status=0x00 (OK)
    raw_response_regex = re.compile(r"\[RAW RESPONSE\]\sCmdType=(0x[0-9a-fA-F]+),\sTargetID=(\d+),\sStatus=(0x[0-9a-fA-F]+)\s\((.+?)\)")

    # --- Data Storage ---
    sensor_data_csvs = defaultdict(list)
    category_timing_data = []
    command_response_data = []

    # --- File Processing ---
    try:
        with open(log_file_path, 'r') as f:
            for line_num, line in enumerate(f, 1):
                line_match = log_line_regex.match(line)
                if not line_match:
                    # Skip lines that don't match the general log format (e.g., help messages, incomplete lines)
                    continue

                timestamp_str, log_level, content = line_match.groups()

                # Try to parse as a RAW SENSOR line
                sensor_match = raw_sensor_regex.match(content)
                if sensor_match:
                    sensor_type_name, sensor_id, values_str, duration_us = sensor_match.groups()
                    
                    sensor_type_name = sensor_type_name.strip()

                    values = [float(v.strip()) for v in values_str.split(',') if v.strip()]
                    
                    record = {
                        'Timestamp': timestamp_str,
                        'Duration_us': int(duration_us),
                        'Duration_s': float(duration_us) / 1_000_000.0
                    }
                    if sensor_type_name == "Pressure":
                        record['Pressure_bar'] = values[0] if values else None
                    elif sensor_type_name == "LoadCell":
                        record['Weight_g'] = values[0] if values else None
                    elif sensor_type_name == "Flow":
                        record['FlowRate_LPM'] = values[0] if values else None
                    elif sensor_type_name == "Temperature":
                        record['Temp_C'] = values[0] if values else None
                        record['Temp_F'] = values[1] if len(values) > 1 else None
                    elif sensor_type_name == "MotorRPM":
                        record['RPM'] = values[0] if values else None
                    else:
                        for i, val in enumerate(values):
                            record[f'Value_{i+1}'] = val
                    
                    file_key = f"{sensor_type_name.lower().replace(' ', '_')}_{sensor_id}"
                    sensor_data_csvs[file_key].append(record)
                    continue

                # Try to parse as a RAW TIMING (Category) line
                timing_match = raw_timing_category_regex.match(content)
                if timing_match:
                    timing_type_id, category_id, duration_us = timing_match.groups()
                    category_timing_data.append({
                        'Timestamp': timestamp_str,
                        'TimingTypeID': timing_type_id,
                        'CategoryID': int(category_id),
                        'Duration_us': int(duration_us),
                        'Duration_s': float(duration_us) / 1_000_000.0
                    })
                    continue

                # Try to parse as a RAW RESPONSE line
                response_match = raw_response_regex.match(content)
                if response_match:
                    original_cmd_type, original_target_id, status_code, status_text = response_match.groups()
                    command_response_data.append({
                        'Timestamp': timestamp_str,
                        'OriginalCmdType': original_cmd_type,
                        'OriginalTargetID': int(original_target_id),
                        'StatusCode': status_code,
                        'StatusText': status_text
                    })
                    continue
                
    except FileNotFoundError:
        print(f"Error: The log file '{log_file_path}' was not found. ‚ùå")
        return
    except Exception as e:
        print(f"An error occurred during file parsing: {e} on line {line_num}. ‚ö†Ô∏è")
        print(f"Problematic line content: {line.strip()}")
        return

    # --- Write Collected Data to CSV Files ---
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created output directory: {output_dir} üìÅ")

    # 1. Write Sensor Data CSVs
    for file_key, records in sensor_data_csvs.items():
        if not records:
            continue
        
        output_file_path = os.path.join(output_dir, f"{file_key}.csv")
        all_headers = set()
        for record in records:
            all_headers.update(record.keys())
        headers = sorted(list(all_headers))
        
        with open(output_file_path, 'w', newline='') as f_out:
            writer = csv.DictWriter(f_out, fieldnames=headers)
            writer.writeheader()
            writer.writerows(records)
        print(f"‚úÖ Successfully created {output_file_path} for {len(records)} entries.")

    # 2. Write Category Timing Data CSV
    if category_timing_data:
        output_file_path = os.path.join(output_dir, "category_timing.csv")
        headers = list(category_timing_data[0].keys())
        with open(output_file_path, 'w', newline='') as f_out:
            writer = csv.DictWriter(f_out, fieldnames=headers)
            writer.writeheader()
            writer.writerows(category_timing_data)
        print(f"‚úÖ Successfully created {output_file_path} for {len(category_timing_data)} entries.")
    else:
        print("No category timing data found to write. üìã")

    # 3. Write Command Response Data CSV
    if command_response_data:
        output_file_path = os.path.join(output_dir, "command_responses.csv")
        headers = list(command_response_data[0].keys())
        with open(output_file_path, 'w', newline='') as f_out:
            writer = csv.DictWriter(f_out, fieldnames=headers)
            writer.writeheader()
            writer.writerows(command_response_data)
        print(f"‚úÖ Successfully created {output_file_path} for {len(command_response_data)} entries.")
    else:
        print("No command response data found to write. üìã")

    print("\nCSV generation complete! ‚ú®")


# --- Example Usage ---
if __name__ == '__main__':
    # Define the log file to use and the directory for CSVs
    input_file = 'Work.log'
    output_folder = "sensor_data_csvs"

    # Run the parser
    parse_log_to_csv(input_file, output_folder)